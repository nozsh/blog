---
draft: false
title: "Starting Flux models locally"
# url: ""
description: "You do not have CLIP state dict!"
summary: "You do not have CLIP state dict!"
date: 2024-09-14
lastmod: 2024-10-20
categories: ["Short Read", "AI"] # ["cat 1", "cat 2"]
tags: ["AI Image Gen"] # ['tag 1', 'tag 2']
author: ["nozsh"] # ['Me', 'You'] multiple authors
authorURL: [""]
# canonicalURL: "yourself"
# weight: 1
# robotsNoIndex: true

# showToc: true
# TocOpen: true
# hidemeta: true
# comments: true
# disableHLJS: true
# disableShare: true
# hideSummary: true
# hideFooter: true
# searchHidden: true
# ShowCodeCopyButtons: false
# ShowReadingTime: false
# ShowWordCount: false
# ShowBreadCrumbs: false
# ShowPostNavLinks: fales
# ShowRssButtonInSectionTermList: false
# ShowCanonicalLink: true
# CanonicalLinkText: "Источник:"
# UseHugoToc: false
# hideAuthor: true
# byai: true
cover:
  image: "@img/start-flux-model-local-cover.webp" # image path/url
  width: "1500" # only for img from url; EX: 1920
  height: "1080" # only for img from url; EX: 1080
  alt: "Starting Flux models locally - Cover" # alt text
  caption: "Cover-Image generated by model - [flux1-dev-bnb-nf4-v2](https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4?sl)" # display caption under cover
  relative: true # when using page bundles set this to true
  hidden: false # only hide on current single page
---

{{< ahtung/badEn >}}

Most likely, you're getting noise or just a blank instead of a beautiful image when trying to generate with the Flux model in [Stable Diffusion web UI by AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui?sl).

Or maybe you're get error **"You do not have CLIP state dict!"** when using the Flux model on another panel.

And that's probably why you're reading this.

{{< callout/warn >}}
This is note about how to run the **Flux** model.<br>  
**Not tutorial on setting up local installation for image generation.**
{{< /callout/warn >}}

{{< embedPost "local-ai-image-generation-stability-matrix">}}

If you're getting noise or blank image, that means your panel doesn't support Flux models.

As of the time of writing, Flux works in [WebUI Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge?sl) and [ComfyUI](https://github.com/comfyanonymous/ComfyUI?sl), both of which are listed in the [Stability Matrix](https://github.com/LykosAI/StabilityMatrix?sl). Also, for now, Flux models work best with NVIDIA GPUs.

{{< callout/note >}}
The **optimized version** of the original Flux model, available [here](https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4?sl), can run out of the box on WebUI Forge.

Because, all the necessary encoders and VAE are already [built-in](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981?sl).
{{< /callout/note >}}

{{% details/1 "Models" %}}
You can download original models from [here](https://huggingface.co/black-forest-labs/FLUX.1-dev?sl) or [here](https://huggingface.co/black-forest-labs/FLUX.1-schnell?sl).

**GGUF versions** are available [here](https://huggingface.co/lllyasviel/FLUX.1-dev-gguf?sl) or [here](https://huggingface.co/lllyasviel/FLUX.1-schnell-gguf?sl).
{{% /details/1 %}}

When running Flux models (or any other models based on Flux), you might run into this error:

```
You do not have CLIP state dict!
```

This happens because the **text encoder** is missing. Someone refer to it as **CLIP**, though technically they're slightly different things.

To make Flux model running, you'll need to download the encoders and VAE.

Download encoders, **clip-l\*** and **t5\*** [from here](https://huggingface.co/comfyanonymous/flux_text_encoders/tree/main?sl).

{{< callout/note >}}
Whether you should use **fp8** or **fp16** depends on your hardware.

If you have low VRAM (4-8GB) and limited RAM (8-16GB), use **fp8**.

If you have mid-range VRAM (11-12GB) and a lot of RAM (32GB+), you can use **fp16**.

If you have plenty of everything, especially VRAM (20GB+), just go with **fp16**.
{{< /callout/note >}}

Now, download the VAE files: `vae/diffusion_pytorch_model.safetensors` and `ae.safetensors` from [here](https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main?sl) or [here](https://huggingface.co/black-forest-labs/FLUX.1-schnell/tree/main?sl).

Place VAE into `models\VAE`, and encoders into `models\text_encoder` or `models\CLIP` (if you're using Stability Matrix).

Now all that's left is to load the VAE and encoders from the menu.

![Load VAE & Text Encoder Menu](@img/001-start-flux-model-local-load-vae-text-encoder-clip.avif)

You can load them in any order.

---

For more details, check out [this discussion](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1050?sl) from the WebUI Forge developer.

